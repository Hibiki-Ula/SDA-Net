optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0001,
  weight_decay : 0.0005
}}

scheduler: {
  type: LambdaLR,
  kwargs: {
  decay_step: 21,
  lr_decay: 0.9,
  lowest_decay: 0.02  # min lr = lowest_decay * lr
}}

bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 21,
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.01
}}


dataset : {
  train : { _base_: cfgs/dataset_configs/PCN.yaml, 
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/PCN.yaml, 
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/PCN.yaml, 
            others: {subset: 'test'}}}

model : {
    NAME: Mamba3d, 
    num_query: 512,
    num_points: 16384,
    center_num: [512, 256],
    global_feature_dim: 1024,
    order: ["xyz", "yzx", "zxy", "hilbert", "z", "z-trans"],
    numorder: 2,
    drop_path_rate: 0.1,
    depth: [6,6],
    decoder_without_lfa: False,
    encoder_type: graph,
    decoder_type: fc,
    center_local_k: 4,
    ordering: False, 
    bimamba_type: "v2",
    transformer_config: {
      trans_dim: 384,
      encoder_dims: 384,
    },
}

total_bs : 16
step_per_update : 1
max_epoch : 300

consider_metric: CDL1